#### Experiment params ########################################################
# hydra:
   # run:
    #name: grin-mlp-MetrLA
    # dir: logs/imputation/${model.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

seed: 1234
workers: 0
# wandb:
#   project: Virtual-Sensing-Multivariate
#   offline: False
#   save_dir: logs/imputation/${model.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
#   experimet:
#       entity: gdefe 

#### Imputation params ########################################################
p_fault: 0.0015
p_noise: 0.05
in_sample: False

whiten_prob: 0.05
prediction_loss_weight: 1.0
impute_only_missing: False
warm_up_steps: 0

#### Dataset params ###########################################################
dataset:
    name: la
    root_dir: '../data/MetrLA'
    splitting:
      val_len: 0.1
      test_len: 0.2
    connectivity:
      method: distance
      threshold: 0.1
      include_self: False
      layout: edge_index
  
# dataset:    
#     name: climateDaily    # climateHourly
#     root_dir: '../data/NASA_data'
#     splitting:
#       val_len: 0.1
#       test_len: 0.2
#     connectivity:
#         method: full
#       # threshold: 0.1
#         include_self: True
#         layout: dense

#### Windowing params #########################################################
window: 24
stride: 1
window_lag: 1
horizon_lag: 1

#### Model params #############################################################
# model:
#   name: grin
#   hparams:
#     hidden_size: 64
#     ff_size: 64
#     kernel_size: 2
#     merge_mode: mlp
    
# model:
#   name: rnni
#   hparams:
#     hidden_size: 64
#     cell: 'gru'
#     concat_mask: True
#     detach_input: False
#     fully_connected: False
#     state_init: 'zero'
    
model:
    name: mymodel
    hparams:
        hidden_size: 16
        embedding_size: 16
        n_conv_layers: 2
        cell: 'gru'
        concat_mask: True
        fully_connected: False
        # n_nodes: 207
        detach_input: False
        state_init: 'zero'
           


#### Training params ##########################################################
epochs: 100     # 300
patience: 40  # 40
limit_train_batches: 160   #160
limit_val_batches: 1.0     #1.0
batch_size: 32
grad_clip_val: 5
scale_target: True
optimizer:
  name: Adam
  hparams:
    lr: 0.001
    weight_decay: 0
lr_scheduler:
  name: CosineAnnealingLR
  hparams:
      eta_min: 0.0001
      T_max: ${ epochs }
